<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="RefRef: A Synthetic Dataset and Benchmark for Reconstructing Refractive and Reflective Objects">
  <meta name="keywords" content="RefRef, R3F, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>RefRef: A Synthetic Dataset and Benchmark for Reconstructing Refractive and Reflective Objects</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="https://cdn.jsdelivr.net/gh/twitter/twemoji@14.0.2/assets/72x72/1f436.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <style>
    .author-block {
      margin-right: 0.9em;
    }
    h1.publication-title.title.is-1 {
      font-size: 2.5rem !important;
      font-family: 'Castoro', sans-serif !important;
    }
  </style>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://github.com/YueYin27">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>
    </div>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title"><span style="font-size:2.2rem;vertical-align:middle;margin-right:0.4em;">üêï</span>RefRef: A Synthetic Dataset and Benchmark for Reconstructing Refractive and Reflective Objects</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><a href="https://github.com/YueYin27" target="_blank">Yue Yin</a></span>
            <span class="author-block"><a href="https://enze-tao.github.io/" target="_blank">Enze Tao</a></span>
            <span class="author-block"><a href="https://weijiandeng.xyz" target="_blank">Weijian Deng</a></span>
            <span class="author-block"><a href="https://sites.google.com/view/djcampbell" target="_blank">Dylan Campbell</a></span>
          </div>
          <div class="is-size-5 has-text-centered" style="margin-top: 1.5em;">
            <a href="https://www.anu.edu.au/" target="_blank">
              <img src="./static/images/Australian_National_University_(emblem).svg.png" alt="ANU Logo" style="height:4em;vertical-align:middle;margin-right:0.5em;">
            </a>
           <div class="is-size-5 has-text-centered" style="margin-top: 1.5em;">
          </div>
          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2505.05848" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2505.05848" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/YueYin27/refref" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://huggingface.co/datasets/yinyue27/RefRef" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <img src="https://huggingface.co/front/assets/huggingface_logo-noborder.svg" alt="Hugging Face" style="height:1em;vertical-align:middle;">
                  </span>
                  <span>Dataset</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Modern 3D reconstruction and novel view synthesis approaches have demonstrated strong performance on scenes with opaque Lambertian objects. 
            However, most assume straight light paths and therefore cannot properly handle refractive and reflective materials. 
            Moreover, datasets specialized for these effects are limited, stymieing efforts to evaluate performance and develop suitable techniques.
          </p>
          <p>
            In this work, we introduce a synthetic RefRef dataset and benchmark for reconstructing scenes with refractive and reflective objects from posed images. 
            Our dataset has 50 such objects of varying complexity, from single-material convex shapes to multi-material non-convex shapes, each placed in three different background types, resulting in 150 scenes. 
            We also propose an oracle method that, given the object geometry and refractive indices, calculates accurate light paths for neural rendering, and an approach based on this that avoids these assumptions. 
            We benchmark these against several state-of-the-art methods and show that all methods lag significantly behind the oracle, highlighting the challenges of the task and dataset.
          </p>
        </div>
      </div>
    </div>
    <div class="has-text-centered" style="margin-top:2em;">
      <img src="./static/images/method.png" alt="Method Teaser" style="max-width:100%; border:1px solid #ccc; border-radius:8px;">
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<!-- Oracle Results -->
<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-4 has-text-centered" style="margin-bottom:1em;">Oracle Results</h2>
      <div id="oracle-carousel" class="carousel results-carousel">
        <div class="item item-oracle-ball">
          <video poster="" id="oracle-ball" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/videos_oracle/Oracle_ball.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-oracle-dog">
          <video poster="" id="oracle-dog" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/videos_oracle/Oracle_dog.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-oracle-ampoule">
          <video poster="" id="oracle-ampoule" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/videos_oracle/Oracle_ampoule.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-oracle-torus">
          <video poster="" id="oracle-torus" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/videos_oracle/Oracle_torus.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-oracle-diffuser">
          <video poster="" id="oracle-diffuser" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/videos_oracle/Oracle_diffuser.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- R3F Results -->
<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-4 has-text-centered" style="margin-bottom:1em;">R3F Results</h2>
      <div id="r3f-carousel" class="carousel results-carousel">
        <div class="item item-ours-ball">
          <video poster="" id="ours-ball" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/videos_ours/ours_ball.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-ours-dog">
          <video poster="" id="ours-dog" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/videos_ours/ours_dog.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-ours-torus">
          <video poster="" id="ours-torus" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/videos_ours/ours_torus.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>

<script>
  document.addEventListener('DOMContentLoaded', function () {
    if (window.bulmaCarousel) {
      bulmaCarousel.attach('#oracle-carousel', { slidesToScroll: 1, slidesToShow: 2, loop: true });
      bulmaCarousel.attach('#r3f-carousel', { slidesToScroll: 1, slidesToShow: 2, loop: true });
    }
  });
</script>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{yin2025refrefsyntheticdatasetbenchmark,
      title={RefRef: A Synthetic Dataset and Benchmark for Reconstructing Refractive and Reflective Objects}, 
      author={Yue Yin and Enze Tao and Weijian Deng and Dylan Campbell},
      year={2025},
      eprint={2505.05848},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2505.05848}, 
}
</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/refref_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/YueYin27/refref" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.<br>
            Website design and code are based on the excellent <a href="https://github.com/nerfies/nerfies.github.io" target="_blank">Nerfies website</a>.<br>
            Special thanks to the Nerfies authors for making their website open source.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
